---
---

@string{aps = {American Physical Society,}}

@inproceedings{cha2024ml2tunerefficientcodetuning,
  bibtex_show={true},
    title={{ML$^2$}Tuner: Efficient Code Tuning via Multi-Level Machine Learning Models}, 
    author={JooHyoung Cha and Munyoung Lee and Jinse Kwon and Jubin Lee and Jemin Lee and Yongin Kwon},
    eprint={2411.10764},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    booktitle={Machine Learning for Systems Workshop at NeurIPS},
    url={https://arxiv.org/abs/2411.10764}, 
    doi={10.48550/arXiv.2411.10764},
    abstract={The increasing complexity of deep learning models necessitates specialized hardware and software optimizations, particularly for deep learning accelerators. Existing autotuning methods often suffer from prolonged tuning times due to profiling invalid configurations, which can cause runtime errors.  We introduce ML$^2$Tuner, a multi-level machine learning tuning technique that enhances autotuning efficiency by incorporating a validity prediction model to filter out invalid configurations and an advanced performance prediction model utilizing hidden features from the compilation process. Experimental results on an extended VTA accelerator demonstrate that ML$^2$Tuner achieves equivalent performance improvements using only 12.3\% of the samples required with a similar approach as TVM and reduces invalid profiling attempts by an average of 60.8\%, Highlighting its potential to enhance autotuning performance by filtering out invalid configurations},
    year={2024},
    month={Dec},
    pdf={paper/2023_12_ACLTuner.pdf},
    selected={true},
    html={https://mlforsystems.org/assets/papers/neurips2024/paper6.pdf},
    abbr={NeurIPS W.},
    pages={1--12},
}

@inproceedings{kwon2023acltuner,
  bibtex_show={true},
  title={{ACLT}uner: A Profiling-Driven Fast Tuning to Optimized Deep Learning Inference},
  author={Yongin Kwon and JooHyoung Cha and Jubin Lee and Misun Yu and Jeman Park and Jemin Lee},
  booktitle={Machine Learning for Systems Workshop at NeurIPS},
  year={2023},
  month={Dec},
  url={https://openreview.net/forum?id=k0FIPHpeR4},
  abstract={Deep learning has expanded its footprint across diverse domains. The performance of these computations hinges on the interplay between deep learning compilers and inference libraries. While compilers adapt efficiently to new deep learning operations or models, their tuning processes are too time-consuming. In con- trast, inference libraries offer quick execution but with adaptability limitations. To address these challenges, we propose ACLTuner, which optimizes execution configurations using existing inference library kernels. ACLTuner identifies and assigns the optimal kernel through targeted device profiling. Compared to ArmNN, AutoTVM, Ansor, ONNXRuntime, and TFLite, ACLTuner not only achieves up to 2.0x faster execution time across seven deep learning models, but also reduces the average tuning time by 95%.},
  pdf={paper/2023_12_ACLTuner.pdf},
  html={https://mlforsystems.org/assets/papers/neurips2023/paper5.pdf},
  abbr={NeurIPS W.},
  pages={1--12},
}

@inproceedings{cha201906imagegenusingga,
    bibtex_show={true},
    title={An Effective Method for Generating Color Images Using Genetic Algorithm}, 
    author={JooHyoung Cha and Young Woon Woo},
    booktitle={2019 INTERNATIONAL CONFERENCE ON FUTURE INFORMATION & COMMUNICATION ENGINEERING Vo.11 No.1},
    issue={1},
    volume={11},
    url={https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE08747485}, 
    abstract={In this paper, we proposed two methods to automatically generate color images similar to existing images using genetic algorithms. Experiments were performed on two different sizes(256x256, 512x512) of color images using each of the proposed methods. Experimental results show that evolving the whole image into sub-images evolves much more effective than modeling and evolving it into a single gene, and the generated images are much more sophisticated. Therefore, we could find that gene modeling should be carefully decided in order to generate an image similar to the existing image in the future, or to learn quickly and naturally to generate an image synthesized from different images.},
    year={2019},
    month={Jun},
    pdf={paper/2019_06_An Effective Method for Generating Color Images Using Genetic Algorithm.pdf},
    html={https://kiice.org/homepage/custom/c2},
    abbr={ICFICE 2019},
    pages={1--4},
}

@inproceedings{cha2022pgoacltuner,
    bibtex_show={true},
    title={Profiling-based ArmCL Optimal Schedule Search for Single-ISA Heterogeneous Multi-Core Architectures}, 
    author={JooHyoung Cha* and Yongin Kwon* and Jemin Lee},
    booktitle={Journal of The Institute of Electronics and Information Engineers},
    issue={7},
    publisher={IEIE},
    doi={10.5573/ieie.2023.60.7.40},
    volume={60},
    journal={Journal of The Institute of Electronics and Information Engineers, ISSN: 2287-5026},
    url={http://journal.auric.kr/ieie/ArticleDetail/RD_R/423544}, 
    abstract={Recently, there has been a growing demand to apply deep learning in embedded environments. In constrained embedded environments, heterogeneous multicore CPU architectures like Arm's big.LITTLE are widely utilized to efficiently carry out deep learning computations. Although Arm provides Arm Compute Library (ACL) for optimal deep learning operations, it does not fully leverage the potential of hardwares with the big.LITTLE structure. This paper proposes a profile-based search method for automatically determining the optimal execution kernel and schedule for each hardware. Experiments were conducted on Tinker Edge R, Odroid N+, and Snapdragon 865 HDK boards using AlexNet, VGG16, MobileNetV2, and GoogleNet models. In all cases, the proposed method improved performance up to 266% compared to existing methods. Through the results of this research, we expect to enable cost-effective, low-power, and high-performance execution of deep learning in embedded devices.},
    year={2022},
    month={Jul},
    pdf={paper/2022_11_단일 ISA 이기종 멀티 코어 구조를 위한 프로파일 기반 ArmCL 최적 스케줄 탐색.pdf},
    html={http://journal.auric.kr/ieie/Archive/202307/7},
    abbr={IEIE J.},
    pages={40--49},
}


@inproceedings{cha2023kiicecloudlaptop,
  abbr={KIICE W.},
  title={**Distinguished Paper** Design of Efficient Virtual Desktop Infrastructure based on Super Resolution and NPU},
  author={JooHyoung Cha and Hyunjun Park and Miseon Im and Beaseop Kwak and Taehyeon Kweon and Bae Seong Jun and Young Woon Woo},
  booktitle={Artificial Intelligence and Applied Workshop at KIICE},
  pages={1--2},
  month = {9},
  year={2023},
  html={https://kiice.org/homepage/custom/w4},
  pdf={paper/2023_09_초해상도_및_기반의_효율적인_가상_데스크톱_인프라_설계.pdf},
}
